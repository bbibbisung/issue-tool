# -*- coding: utf-8 -*-
"""
issue_train.py

1) Excel ë°ì´í„°(issues_dataset.xlsx)ë¥¼ ì½ì–´ì„œ
2) issue / non_issue ë¼ë²¨ì„ ìƒì„±í•˜ê³ 
3) Logistic Regression ëª¨ë¸ì„ í•™ìŠµí•œ ë’¤
4) issue_classifier.pkl ë¡œ ì €ì¥.
5) ë™ì‹œì— "ì–´ë–¤ ì˜ˆì‹œê°€ ì–´ë–¤ ê²€ìˆ˜-í”¼ë“œë°± ì„¤ëª…ì„ ê°–ëŠ”ì§€" ë¥¼
   process_lookup.pkl ë¡œ ì €ì¥í•˜ì—¬, ë‚˜ì¤‘ì— ìœ ì‚¬ë„ ê¸°ë°˜ í”„ë¡œì„¸ìŠ¤ ë§¤ì¹­ì— ì‚¬ìš©.

ê°™ì€ í´ë”ì— issues_dataset.xlsx íŒŒì¼ì„ ë‘ê³  ì‹¤í–‰í•˜ì„¸ìš”.
"""

import os
import joblib
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
EXCEL_PATH = os.path.join(BASE_DIR, "issues_dataset.xlsx")
CSV_PATH = os.path.join(BASE_DIR, "issues_dataset.csv")
MODEL_PATH = os.path.join(BASE_DIR, "issue_classifier.pkl")
LOOKUP_PATH = os.path.join(BASE_DIR, "process_lookup.pkl")


def make_label(row) -> str:
    """
    ì—‘ì…€ì˜ 'ì´ìŠˆ íŒë‹¨' + 'ê²€ìˆ˜ - í”¼ë“œë°±' ì»¬ëŸ¼ì„ ì´ìš©í•´
    ìµœì¢… ë¼ë²¨(issue / non_issue)ì„ ë§Œë“­ë‹ˆë‹¤.
    """
    value = str(row.get("ì´ìŠˆ íŒë‹¨", "")).strip().upper()

    if value == "O":
        return "issue"
    if value == "X":
        return "non_issue"

    # í˜¹ì‹œ ëª¨ë¥¼ ì˜ˆì™¸ ìƒí™©: 'ì´ìŠˆê°€ ì•„ë‹Œ' ë“± ë¬¸êµ¬ë¡œ íŒë‹¨
    feedback = str(row.get("ê²€ìˆ˜ - í”¼ë“œë°±", ""))
    negative_patterns = [
        "ì´ìŠˆê°€ ì•„ë‹Œ",
        "ì „ë‹¬í•  í•„ìš” ì—†ìŠµë‹ˆë‹¤",
        "ì „ë‹¬í•˜ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤",
        "ì´ìŠˆ ì „ë‹¬ í•„ìš”ê±´ì´ ì•„ë‹™ë‹ˆë‹¤",
    ]
    for pat in negative_patterns:
        if pat in feedback:
            return "non_issue"

    # ê¸°ë³¸ê°’ì€ issue ìª½ìœ¼ë¡œ ë³´ìˆ˜ì ìœ¼ë¡œ ì²˜ë¦¬
    return "issue"


def load_dataset() -> pd.DataFrame:
    if not os.path.exists(EXCEL_PATH):
        raise FileNotFoundError(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {EXCEL_PATH}")

    df = pd.read_excel(EXCEL_PATH)
    required_cols = ["ê²Œì„ëª…", "ì œëª©/ë‚´ìš©", "ì´ìŠˆ íŒë‹¨", "ê²€ìˆ˜ - í”¼ë“œë°±"]
    for col in required_cols:
        if col not in df.columns:
            raise KeyError(f"ì—‘ì…€ì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")

    # ë¼ë²¨ ìƒì„±
    df["label"] = df.apply(make_label, axis=1)

    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬(ê°„ë‹¨í•˜ê²Œ ì¤„ë°”ê¿ˆ ì œê±° ì •ë„ë§Œ)
    df["text"] = df["ì œëª©/ë‚´ìš©"].astype(str).str.replace(r"\s+", " ", regex=True)

    # CSVë¡œë„ ì €ì¥ (ë°±ì—… ë° ì™¸ë¶€ í™•ì¸ìš©)
    df.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")

    return df


def train_and_save(df: pd.DataFrame):
    X = df["text"]
    y = df["label"]

    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=42,
        stratify=y,
    )

    pipeline = Pipeline(
        steps=[
            ("tfidf", TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
            (
                "clf",
                LogisticRegression(
                    max_iter=300,
                    class_weight="balanced",  # ë°ì´í„° ë¶ˆê· í˜• ë³´ì •
                ),
            ),
        ]
    )

    print("ğŸ“˜ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    pipeline.fit(X_train, y_train)

    print("ğŸ“˜ ê²€ì¦ ë°ì´í„° í‰ê°€:")
    y_pred = pipeline.predict(X_test)
    print(classification_report(y_test, y_pred))

    # 1) ë¶„ë¥˜ ëª¨ë¸ ì €ì¥
    joblib.dump(pipeline, MODEL_PATH)
    print(f"âœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ ë‹¤ìŒ ìœ„ì¹˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {MODEL_PATH}")

    # 2) í”„ë¡œì„¸ìŠ¤ ë§¤ì¹­ìš© lookup ë°ì´í„° ìƒì„± & ì €ì¥
    #    - ê°™ì€ tfidf ë²¡í„° ê³µê°„ì—ì„œ ì˜ˆì‹œ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•¨
    tfidf = pipeline.named_steps["tfidf"]
    X_all_tfidf = tfidf.transform(df["text"])

    lookup = {
        "texts": list(df["text"]),                 # ì œëª©/ë‚´ìš© í…ìŠ¤íŠ¸
        "games": list(df["ê²Œì„ëª…"]),               # ê²Œì„ëª… (NK / FM ë“±)
        "feedback": list(df["ê²€ìˆ˜ - í”¼ë“œë°±"]),      # êµìœ¡ìš© ê²€ìˆ˜-í”¼ë“œë°± ì„¤ëª…
        "labels": list(df["label"]),              # issue / non_issue
        "X_tfidf": X_all_tfidf,                   # ì „ì²´ ì˜ˆì‹œ ë²¡í„°
    }

    joblib.dump(lookup, LOOKUP_PATH)
    print(f"âœ… í”„ë¡œì„¸ìŠ¤ ë§¤ì¹­ìš© lookup ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {LOOKUP_PATH}")


def main():
    print("1) ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ë¼ë²¨ ìƒì„±...")
    df = load_dataset()
    print(f"   - ì´ ìƒ˜í”Œ ìˆ˜: {len(df)}")
    print(df["label"].value_counts())

    print("\n2) ëª¨ë¸ í•™ìŠµ ë° lookup ë°ì´í„° ìƒì„±...")
    train_and_save(df)


if __name__ == "__main__":
    main()
